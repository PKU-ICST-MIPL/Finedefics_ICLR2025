<!-- PROJECT LOGO -->

<p align="center">
  <h1 align="center">Analyzing and Boosting the Power of Fine-Grained Visual Recognition for Multi-modal Large Language Models</h1>
  <p align="center">
    <a href="http://39.108.48.32/mipl/news/news.php?id=CHhehulingxiao"><strong>Hulingxiao He</strong></a>
    路
    <a href="http://39.108.48.32/mipl/news/news.php?id=CHligeng"><strong>Geng Li</strong></a>
    路
    <a href="http://39.108.48.32/mipl/news/news.php?id=CHgengzijun"><strong>Zijun Geng</strong></a>
    路
    <a href="http://39.108.48.32/XuWebsite/"><strong>Jinglin Xu</strong></a>
    路
    <a href="http://39.108.48.32/mipl/pengyuxin"><strong>Yuxin Peng</strong></a>
  </p>
  <h2 align="center">ICLR 2025</h2>
  <h3 align="center"><a href="https://arxiv.org/abs/2401.13837">Paper</a> | <a href="https://openreview.net/forum?id=c7DND1iIgb">OpenReview</a> </h3>
<div align="center"></div>
<p align="center">
  <p>
  <strong>TL;DR</strong>: We revisit three quintessential capabilities of MLLMs for FGVR, including object information extraction, category knowledge reserve, object-category alignment, and position of the root cause as <strong> a misalignment problem</strong>. To address this issue, we present <strong> Finedefics</strong>, an MLLM that enhances the model's FGVR capability by incorporating informative attribute descriptions of objects into the training phase. 
  </p>
  <a href="">
    <img src="figures/pipeline.png" alt="Logo" width="100%">
  </a>
<br>


##  News:
- [01/23/2025] Our work is accepted to <a href="https://iclr.cc/Conferences/2025"><strong>ICLR 2025</strong></a> ! Code is coming soon. See you in Singapore this April!



##  Citation
Should you find our paper valuable to your work, we would greatly appreciate it if you could cite it:
```bibtex
@inproceedings{
    he2025analyzing,
    title={Analyzing and Boosting the Power of Fine-Grained Visual Recognition for Multi-modal Large Language Models},
    author={Hulingxiao He and Geng Li and Zijun Geng and Jinglin Xu and Yuxin Peng},
    booktitle={The Thirteenth International Conference on Learning Representations},
    year={2025},
    url={https://openreview.net/forum?id=p3NKpom1VL}
}
```